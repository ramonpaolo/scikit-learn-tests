{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486f5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe17dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9919be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, but, good\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db999cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression(max_iter=200).fit(X, y)\n",
    "model = LogisticRegression(max_iter=200).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35629bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "141a4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados previstos:  [1 1 1 2 2 0 1 1 0 1 0 0 1 1 2 2 0 2 0 1 2 2 2 1 0 2 0 2 2 0]\n",
      "Dados reais:  [1 1 1 2 2 0 1 1 0 1 0 0 1 1 2 2 0 2 0 1 2 2 2 1 0 2 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dados previstos: \", predict)\n",
    "print(\"Dados reais: \", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f88d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtdTruth = 0\n",
    "qtdTest = len(y_test)\n",
    "for x in range(qtdTest):\n",
    "    if y_test[x] == predict[x]:\n",
    "        qtdTruth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19af3be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c9320d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtdTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32a85c",
   "metadata": {},
   "source": [
    "De 30 testes realizados, 29 deles deram 'match' com o valor previsto. Isso dá uma precisão de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "845a2a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regra de 3 básica\n",
    "## 29 é o número que temos, e 30 simboliza os 100%, logo, 29*100 dividido por 30, dá a porcentagem total de 'accuracy'\n",
    "accuracy = ((29*100)/30)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779aa8b",
   "metadata": {},
   "source": [
    "# Como salvar o modelo?\n",
    "Bom, antes de mostrar como salvar, é importante dizer do porquê salvar o modelo.\n",
    "\n",
    "O modelo deve ser salvo, quando sabemos que ele já está pronto e funcional para um ambiente de produção, para ser carregado em uma máquina de produção(na AWS, em contato com o cliente final por exemplo).\n",
    "\n",
    "Nós salvamos o modelo, para que ele não precise gastar tempo e poder(energia) computacional, fazendo(construindo) o nosso modelo do absoluto zero. Dependendo do tamanho, isso pode durar MUITOOOO tempo, e não temos esse tempo todo para esperar, pois toda hora que fossemos executar o código, com um F5 no VSCode, ou executar a 'row' no Jupyter, ele iria carregar tudo de novo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5160728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8d42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = \"training_model.plk\"\n",
    "with open(name_file, \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109210b",
   "metadata": {},
   "source": [
    "Utilizamos a lib *pickle* para salvar o modelo, logo, podemos recuperar o modelo, em qualquer código, e rapidamente, ao invés de termos que treinar o nosso próprio modelo toda vez. Ele já está pronto, tanto que você pode compartilhar ele facilmente no github, ou em grupos(como Discord) rapidamente e facilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a1c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name_file, \"rb\") as file:\n",
    "    modelLocal = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60ea482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 2, 2, 0, 2, 0, 1, 2, 2,\n",
       "       2, 1, 0, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLocal.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a3573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893aeba",
   "metadata": {},
   "source": [
    "Como podemos ver, o modelo salvo, funciona normalmente.\n",
    "\n",
    "Claro, em uma aplicação simples como a nossa, não terá tanta diferença assim, ainda mais uma de exemplo. Mas imagine isso, com centenas de milhares de dados, algo que o computador levaria segundos, minutos ou até mesmo horas, por cada execução da 'row' ou F5 clicado no VSCode. Sem dúvida alguma, saber como salvar o modelo, em forma de arquivo, é um tanto como *obrigatório*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
